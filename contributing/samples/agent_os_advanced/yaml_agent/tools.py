# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import subprocess
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from google.adk.tools.tool_context import ToolContext


# Root Agent Tools
def create_project_folder(
    project_name: str,
    project_description: str,
    tool_context: ToolContext
) -> str:
    """Create a dedicated project folder with Agent OS structure.
    
    Args:
        project_name: Name of the project
        project_description: Brief description of the project
        
    Returns:
        Status message about project folder creation
    """
    # Create project folder with sanitized name
    safe_name = project_name.lower().replace(' ', '-').replace('_', '-')
    project_folder = Path(safe_name)
    
    # Create main project directory
    project_folder.mkdir(exist_ok=True)
    
    # Create Agent OS structure within project folder
    agent_os_dir = project_folder / ".agent-os"
    product_dir = agent_os_dir / "product"
    specs_dir = agent_os_dir / "specs"
    standards_dir = agent_os_dir / "standards"
    instructions_dir = agent_os_dir / "instructions" / "core"
    
    # Create all directories
    for directory in [product_dir, specs_dir, standards_dir, instructions_dir]:
        directory.mkdir(parents=True, exist_ok=True)
    
    # Create project README
    readme_content = f"""# {project_name}

{project_description}

## Project Structure

This project follows Agent OS conventions:

```
{project_folder.name}/
├── .agent-os/
│   ├── product/           # Product documentation
│   ├── specs/            # Technical specifications
│   ├── standards/        # Development standards
│   └── instructions/     # Workflow instructions
├── src/                  # Source code
├── tests/                # Test files
└── docs/                 # Additional documentation
```

## Getting Started

1. Review the product mission in `.agent-os/product/`
2. Check available specifications in `.agent-os/specs/`
3. Follow Agent OS workflow commands for development

## Agent OS Commands

- `@analyze-product` - Analyze existing product codebase
- `@plan-product` - Plan new product development
- `@create-spec` - Create technical specifications
- `@create-tasks` - Break down specs into tasks
- `@execute-tasks` - Execute development tasks
- `@execute-task` - Execute specific task

---
*Generated by Agent OS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    readme_file = project_folder / "README.md"
    readme_file.write_text(readme_content)
    
    # Create basic project structure
    src_dir = project_folder / "src"
    tests_dir = project_folder / "tests"
    docs_dir = project_folder / "docs"
    
    for directory in [src_dir, tests_dir, docs_dir]:
        directory.mkdir(exist_ok=True)
    
    # Create .gitignore
    gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
venv/
env/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Agent OS
.agent-os/temp/
.agent-os/cache/

# Project specific
*.log
.env
"""
    
    gitignore_file = project_folder / ".gitignore"
    gitignore_file.write_text(gitignore_content)
    
    return f"""✅ **Project Folder Created**: {project_folder.name}

**Location**: {project_folder.absolute()}
**Agent OS Structure**: ✅ Initialized
**Project Files**: README.md, .gitignore, src/, tests/, docs/

**Next Steps**:
1. Navigate to the project folder: `cd {project_folder.name}`
2. Run Agent OS commands from within the project
3. All generated files will be organized within this folder

**Agent OS Commands Available**:
- @analyze-product - Analyze existing codebase
- @plan-product - Plan new product development
- @create-spec - Create technical specifications
- @create-tasks - Break down specs into tasks
- @execute-tasks - Execute development tasks
- @execute-task - Execute specific task
"""


def create_product_mission(
    product_name: str,
    description: str,
    target_users: str,
    key_features: List[str],
    project_folder: Optional[str] = None,
    tool_context: ToolContext = None
) -> str:
    """Create a product mission document following Agent OS structure.
    
    Args:
        product_name: Name of the product
        description: Brief product description
        target_users: Description of target user base
        key_features: List of key product features
        project_folder: Optional project folder path (if None, uses current directory)
        
    Returns:
        Status message about mission creation
    """
    # Determine the base directory
    if project_folder:
        base_dir = Path(project_folder)
    else:
        base_dir = Path(".")
    
    mission_content = f"""# Product Mission

## Pitch

{description}

## Target Users

{target_users}

## Key Features

{chr(10).join(f"- {feature}" for feature in key_features)}

## Success Metrics

- User adoption rate
- Feature utilization
- User satisfaction scores
- Performance benchmarks

## Timeline

- Phase 1: Core functionality (Month 1-2)
- Phase 2: Advanced features (Month 3-4)
- Phase 3: Optimization & scaling (Month 5-6)
"""

    # Create .agent-os directory structure
    agent_os_dir = base_dir / ".agent-os"
    product_dir = agent_os_dir / "product"
    product_dir.mkdir(parents=True, exist_ok=True)
    
    # Write mission file
    mission_file = product_dir / "mission.md"
    mission_file.write_text(mission_content)
    
    # Create mission-lite.md
    mission_lite = f"""# {product_name}

{description}

**Target Users**: {target_users}

**Key Features**: {', '.join(key_features)}
"""
    
    mission_lite_file = product_dir / "mission-lite.md"
    mission_lite_file.write_text(mission_lite)
    
    # Create tech-stack.md placeholder
    tech_stack_content = f"""# Technical Stack

## Application Framework
- Framework: [To be determined]
- Version: [To be determined]

## Database System
- Database: [To be determined]
- Version: [To be determined]

## Frontend
- JavaScript Framework: [To be determined]
- CSS Framework: [To be determined]

## Deployment
- Hosting: [To be determined]
- CI/CD: [To be determined]

---
*This will be populated during the planning phase*
"""
    
    tech_stack_file = product_dir / "tech-stack.md"
    tech_stack_file.write_text(tech_stack_content)
    
    # Create roadmap.md placeholder
    roadmap_content = f"""# Product Roadmap

## Phase 1: Core Functionality
**Goal**: Implement essential features
**Success Criteria**: Basic functionality working

### Features
- [ ] {key_features[0] if key_features else 'Core Feature 1'}
- [ ] {key_features[1] if len(key_features) > 1 else 'Core Feature 2'}
- [ ] {key_features[2] if len(key_features) > 2 else 'Core Feature 3'}

## Phase 2: Advanced Features
**Goal**: Add advanced functionality
**Success Criteria**: Enhanced user experience

### Features
- [ ] Advanced Feature 1
- [ ] Advanced Feature 2
- [ ] Advanced Feature 3

## Phase 3: Optimization & Scaling
**Goal**: Performance and scalability
**Success Criteria**: Production-ready system

### Features
- [ ] Performance optimization
- [ ] Scalability improvements
- [ ] Security hardening
"""
    
    roadmap_file = product_dir / "roadmap.md"
    roadmap_file.write_text(roadmap_content)
    
    return f"""✅ **Product Mission Created**: {product_name}

**Location**: {product_dir.absolute()}
**Files Created**:
- mission.md - Complete product mission
- mission-lite.md - Condensed mission summary
- tech-stack.md - Technical stack placeholder
- roadmap.md - Development roadmap

**Next Steps**:
1. Review and customize the mission documents
2. Update tech-stack.md with your technology choices
3. Modify roadmap.md based on your priorities
4. Use @create-spec to create detailed specifications
"""


def create_technical_spec(
    feature_name: str,
    requirements: str,
    acceptance_criteria: List[str],
    project_folder: Optional[str] = None,
    tool_context: ToolContext = None
) -> str:
    """Create a detailed technical specification.
    
    Args:
        feature_name: Name of the feature
        requirements: Detailed requirements description
        acceptance_criteria: List of acceptance criteria
        project_folder: Optional project folder path (if None, uses current directory)
        
    Returns:
        Status message about spec creation
    """
    # Determine the base directory
    if project_folder:
        base_dir = Path(project_folder)
    else:
        base_dir = Path(".")
    
    date_str = datetime.now().strftime("%Y-%m-%d")
    spec_name = f"{date_str}-{feature_name.lower().replace(' ', '-')}"
    
    spec_content = f"""# {feature_name} Specification

## Overview

{requirements}

## Technical Requirements

### Functional Requirements
- Core functionality implementation
- User interface components
- Data handling and storage
- Integration points

### Non-Functional Requirements
- Performance benchmarks
- Security considerations
- Scalability requirements
- Accessibility standards

## Acceptance Criteria

{chr(10).join(f"- {criteria}" for criteria in acceptance_criteria)}

## Implementation Plan

### Phase 1: Foundation
- Set up project structure
- Implement core components
- Basic functionality

### Phase 2: Enhancement
- Advanced features
- User interface polish
- Integration testing

### Phase 3: Optimization
- Performance tuning
- Security hardening
- Documentation

## Testing Strategy

- Unit tests for core functionality
- Integration tests for system components
- User acceptance testing
- Performance testing

## Dependencies

- External libraries and frameworks
- Third-party services
- Infrastructure requirements

## Risks and Mitigation

- Technical risks and solutions
- Timeline risks and contingencies
- Resource constraints and alternatives
"""

    # Create spec directory
    agent_os_dir = base_dir / ".agent-os"
    specs_dir = agent_os_dir / "specs" / spec_name
    specs_dir.mkdir(parents=True, exist_ok=True)
    
    # Write spec file
    spec_file = specs_dir / "spec.md"
    spec_file.write_text(spec_content)
    
    # Create spec-lite.md
    spec_lite = f"""# {feature_name}

{requirements}

## Acceptance Criteria
{chr(10).join(f"- {criteria}" for criteria in acceptance_criteria)}
"""
    
    spec_lite_file = specs_dir / "spec-lite.md"
    spec_lite_file.write_text(spec_lite)
    
    # Create sub-specs directory and technical spec
    sub_specs_dir = specs_dir / "sub-specs"
    sub_specs_dir.mkdir(exist_ok=True)
    
    tech_spec_content = f"""# Technical Specification - {feature_name}

## Architecture

[Technical architecture details to be defined]

## Implementation Details

[Detailed implementation steps]

## Dependencies

[External dependencies and requirements]

## API Design

[API endpoints and interfaces]

## Database Schema

[Database design and relationships]

## Security Considerations

[Security requirements and implementation]

---
*This technical specification will be detailed during implementation*
"""
    
    tech_spec_file = sub_specs_dir / "technical-spec.md"
    tech_spec_file.write_text(tech_spec_content)
    
    return f"""✅ **Technical Specification Created**: {feature_name}

**Location**: {specs_dir.absolute()}
**Files Created**:
- spec.md - Complete specification
- spec-lite.md - Condensed specification
- sub-specs/technical-spec.md - Technical details

**Next Steps**:
1. Review and customize the specification
2. Use @create-tasks to break down into actionable tasks
3. Use @execute-tasks to implement the feature
"""


def create_task_breakdown(
    spec_name: str,
    tasks: List[str],
    project_folder: Optional[str] = None,
    tool_context: ToolContext = None
) -> str:
    """Create a task breakdown for a specification.
    
    Args:
        spec_name: Name of the specification
        tasks: List of tasks to complete
        project_folder: Optional project folder path (if None, uses current directory)
        
    Returns:
        Status message about task creation
    """
    # Determine the base directory
    if project_folder:
        base_dir = Path(project_folder)
    else:
        base_dir = Path(".")
    
    date_str = datetime.now().strftime("%Y-%m-%d")
    spec_folder = f"{date_str}-{spec_name.lower().replace(' ', '-')}"
    
    tasks_content = f"""# {spec_name} - Task Breakdown

## Tasks

{chr(10).join(f"- [ ] {task}" for task in tasks)}

## Task Status

- **Total Tasks**: {len(tasks)}
- **Completed**: 0
- **In Progress**: 0
- **Pending**: {len(tasks)}

## Notes

- Tasks should be completed in order when possible
- Mark tasks as complete with [x] when finished
- Add notes and comments as needed

## Completion Criteria

All tasks must be completed and tested before marking the specification as done.

## Implementation Guidelines

1. **Code Quality**: Follow project coding standards
2. **Testing**: Write tests for each task
3. **Documentation**: Update documentation as needed
4. **Git Workflow**: Create feature branches for each task
5. **Review**: Code review before marking complete

## Dependencies

- Ensure all dependencies are installed
- Check for conflicts with existing code
- Verify integration points

---
*Generated by Agent OS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    # Find or create spec directory
    agent_os_dir = base_dir / ".agent-os"
    specs_dir = agent_os_dir / "specs" / spec_folder
    specs_dir.mkdir(parents=True, exist_ok=True)
    
    # Write tasks file
    tasks_file = specs_dir / "tasks.md"
    tasks_file.write_text(tasks_content)
    
    # Create implementation notes file
    implementation_notes = f"""# Implementation Notes - {spec_name}

## Development Environment

- **Project Folder**: {base_dir.absolute()}
- **Specification**: {spec_folder}
- **Created**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Quick Start

1. Navigate to project folder: `cd {base_dir.name if base_dir.name != '.' else 'current directory'}`
2. Review tasks in `.agent-os/specs/{spec_folder}/tasks.md`
3. Start with the first task
4. Use @execute-task to work on specific tasks

## File Structure

```
{base_dir.name}/
├── .agent-os/
│   └── specs/
│       └── {spec_folder}/
│           ├── spec.md
│           ├── spec-lite.md
│           ├── tasks.md
│           ├── implementation-notes.md
│           └── sub-specs/
│               └── technical-spec.md
├── src/                  # Source code
├── tests/                # Test files
└── docs/                 # Documentation
```

## Task Management

- Mark completed tasks with `[x]`
- Add progress notes in tasks.md
- Update implementation-notes.md with details
- Create git branches for each major task

---
*This file helps track implementation progress*
"""
    
    notes_file = specs_dir / "implementation-notes.md"
    notes_file.write_text(implementation_notes)
    
    return f"""✅ **Task Breakdown Created**: {spec_name}

**Location**: {specs_dir.absolute()}
**Files Created**:
- tasks.md - Task breakdown with {len(tasks)} tasks
- implementation-notes.md - Implementation guidance

**Next Steps**:
1. Review the task breakdown
2. Use @execute-task to work on specific tasks
3. Use @execute-tasks to work through all tasks systematically
4. Update task status as you complete them

**Available Commands**:
- @execute-task [task_number] - Work on a specific task
- @execute-tasks - Execute all tasks in order
- @analyze-project - Check project status
"""


def analyze_project_structure(
    project_path: str,
    tool_context: ToolContext
) -> str:
    """Analyze the current project structure and provide insights.
    
    Args:
        project_path: Path to the project directory to analyze
        
    Returns:
        Analysis of the project structure
    """
    current_dir = Path(project_path)
    
    # Analyze directory structure
    directories = []
    files = []
    
    for item in current_dir.rglob("*"):
        if item.is_dir() and not item.name.startswith('.'):
            directories.append(str(item))
        elif item.is_file() and not item.name.startswith('.'):
            files.append(str(item))
    
    # Check for Agent OS structure
    agent_os_dir = Path(".agent-os")
    has_agent_os = agent_os_dir.exists()
    
    analysis = f"""# Project Structure Analysis

## Overview
- **Total Directories**: {len(directories)}
- **Total Files**: {len(files)}
- **Agent OS Structure**: {'✅ Present' if has_agent_os else '❌ Missing'}

## Directory Structure
{chr(10).join(f"- {d}" for d in sorted(directories)[:10])}
{'...' if len(directories) > 10 else ''}

## Key Files
{chr(10).join(f"- {f}" for f in sorted(files)[:10])}
{'...' if len(files) > 10 else ''}

## Agent OS Status
"""

    if has_agent_os:
        # Analyze Agent OS structure
        product_dir = agent_os_dir / "product"
        specs_dir = agent_os_dir / "specs"
        
        analysis += f"""
- **Product Directory**: {'✅' if product_dir.exists() else '❌'}
- **Specs Directory**: {'✅' if specs_dir.exists() else '❌'}
"""
        
        if specs_dir.exists():
            specs = list(specs_dir.iterdir())
            analysis += f"- **Specifications**: {len(specs)} found\n"
            for spec in specs[:5]:
                analysis += f"  - {spec.name}\n"
    else:
        analysis += """
- Agent OS structure not initialized
- Run @plan-product to set up the structure
"""

    return analysis


def analyze_existing_product(
    project_path: str,
    product_context: str,
    tool_context: ToolContext
) -> str:
    """Analyze an existing product codebase and prepare for Agent OS installation.
    
    This tool performs a comprehensive analysis of an existing codebase to understand:
    - Current project structure and organization
    - Technology stack and dependencies
    - Implemented features and progress
    - Code patterns and conventions
    - Development workflow and practices
    
    Args:
        project_path: Path to the project directory to analyze
        product_context: Additional context about the product (vision, users, etc.)
        
    Returns:
        Comprehensive analysis report for Agent OS installation
    """
    current_dir = Path(project_path)
    
    # Analyze directory structure
    directories = []
    files = []
    config_files = []
    source_files = []
    
    for item in current_dir.rglob("*"):
        if item.is_dir() and not item.name.startswith('.'):
            directories.append(str(item))
        elif item.is_file() and not item.name.startswith('.'):
            files.append(str(item))
            
            # Identify configuration files
            if item.suffix in ['.json', '.yaml', '.yml', '.toml', '.ini', '.cfg']:
                config_files.append(str(item))
            # Identify source code files
            elif item.suffix in ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.go', '.rs', '.cpp', '.c']:
                source_files.append(str(item))
    
    # Analyze package/dependency files
    package_files = []
    for file in files:
        if any(name in file.lower() for name in ['package.json', 'requirements.txt', 'gemfile', 'cargo.toml', 'go.mod', 'pom.xml']):
            package_files.append(file)
    
    # Check for Agent OS structure
    agent_os_dir = Path(".agent-os")
    has_agent_os = agent_os_dir.exists()
    
    # Analyze technology stack
    tech_stack = {
        'languages': set(),
        'frameworks': set(),
        'databases': set(),
        'tools': set()
    }
    
    for file in source_files:
        if file.endswith('.py'):
            tech_stack['languages'].add('Python')
        elif file.endswith(('.js', '.jsx')):
            tech_stack['languages'].add('JavaScript')
        elif file.endswith(('.ts', '.tsx')):
            tech_stack['languages'].add('TypeScript')
        elif file.endswith('.java'):
            tech_stack['languages'].add('Java')
        elif file.endswith('.go'):
            tech_stack['languages'].add('Go')
        elif file.endswith('.rs'):
            tech_stack['languages'].add('Rust')
    
    # Analyze configuration files for frameworks
    for config_file in config_files:
        try:
            content = Path(config_file).read_text()
            if 'package.json' in config_file:
                if 'react' in content.lower():
                    tech_stack['frameworks'].add('React')
                if 'vue' in content.lower():
                    tech_stack['frameworks'].add('Vue')
                if 'angular' in content.lower():
                    tech_stack['frameworks'].add('Angular')
                if 'express' in content.lower():
                    tech_stack['frameworks'].add('Express')
            elif 'requirements.txt' in config_file:
                if 'django' in content.lower():
                    tech_stack['frameworks'].add('Django')
                if 'flask' in content.lower():
                    tech_stack['frameworks'].add('Flask')
                if 'fastapi' in content.lower():
                    tech_stack['frameworks'].add('FastAPI')
        except:
            pass
    
    analysis = f"""# Existing Product Analysis

## Product Context
{product_context}

## Project Overview
- **Total Directories**: {len(directories)}
- **Total Files**: {len(files)}
- **Source Files**: {len(source_files)}
- **Configuration Files**: {len(config_files)}
- **Agent OS Structure**: {'✅ Present' if has_agent_os else '❌ Missing'}

## Technology Stack Analysis

### Programming Languages
{chr(10).join(f"- {lang}" for lang in sorted(tech_stack['languages']))}

### Frameworks & Libraries
{chr(10).join(f"- {fw}" for fw in sorted(tech_stack['frameworks'])) if tech_stack['frameworks'] else "- None detected"}

### Package Management
{chr(10).join(f"- {pkg}" for pkg in package_files) if package_files else "- No package files detected"}

## Project Structure
{chr(10).join(f"- {d}" for d in sorted(directories)[:15])}
{'...' if len(directories) > 15 else ''}

## Key Source Files
{chr(10).join(f"- {f}" for f in sorted(source_files)[:10])}
{'...' if len(source_files) > 10 else ''}

## Agent OS Installation Status
"""
    
    if has_agent_os:
        # Analyze existing Agent OS structure
        product_dir = agent_os_dir / "product"
        specs_dir = agent_os_dir / "specs"
        
        analysis += f"""
- **Product Directory**: {'✅' if product_dir.exists() else '❌'}
- **Specs Directory**: {'✅' if specs_dir.exists() else '❌'}
"""
        
        if specs_dir.exists():
            specs = list(specs_dir.iterdir())
            analysis += f"- **Specifications**: {len(specs)} found\n"
            for spec in specs[:5]:
                analysis += f"  - {spec.name}\n"
    else:
        analysis += """
- Agent OS structure not initialized
- Ready for Agent OS installation
- Will create .agent-os/product/ structure
- Will analyze existing features for roadmap
"""

    analysis += f"""

## Recommended Next Steps

1. **Install Agent OS**: Run @plan-product with gathered context
2. **Create Mission**: Document product vision and target users
3. **Build Roadmap**: Map existing features to development phases
4. **Set Up Specs**: Create specifications for planned features

## Analysis Summary

This codebase appears to be a {', '.join(sorted(tech_stack['languages']))} project with {len(source_files)} source files. 
{'The project already has Agent OS installed.' if has_agent_os else 'The project is ready for Agent OS installation.'}

**Key Findings**:
- Technology stack: {', '.join(sorted(tech_stack['languages']))}
- {'Frameworks detected: ' + ', '.join(sorted(tech_stack['frameworks'])) if tech_stack['frameworks'] else 'No major frameworks detected'}
- Project structure: {len(directories)} directories, {len(files)} total files
- Development stage: {'Active development' if len(source_files) > 10 else 'Early stage'}

This analysis provides the foundation for setting up Agent OS with documentation that reflects the actual implementation.
"""

    return analysis


# Claude Code Agent Tools
def create_file_structure(
    project_name: str,
    structure: Dict[str, str],
    tool_context: ToolContext
) -> str:
    """Create a file and directory structure for a project.
    
    Args:
        project_name: Name of the project
        structure: Dictionary mapping file paths to content
        
    Returns:
        Status message about structure creation
    """
    created_files = []
    created_dirs = []
    
    for file_path, content in structure.items():
        path = Path(file_path)
        
        # Create parent directories
        if path.parent != Path("."):
            path.parent.mkdir(parents=True, exist_ok=True)
            if str(path.parent) not in created_dirs:
                created_dirs.append(str(path.parent))
        
        # Create file
        path.write_text(content)
        created_files.append(str(path))
    
    return f"""🔨 **Creating**: Project structure for {project_name}

**Created Directories**: {len(created_dirs)}
{chr(10).join(f"- {d}" for d in created_dirs)}

**Created Files**: {len(created_files)}
{chr(10).join(f"- {f}" for f in created_files)}

✅ **Completed**: File structure creation"""


def implement_feature(
    feature_name: str,
    implementation_details: str,
    file_changes: Dict[str, str],
    tool_context: ToolContext
) -> str:
    """Implement a specific feature with file changes.
    
    Args:
        feature_name: Name of the feature to implement
        implementation_details: Details about the implementation
        file_changes: Dictionary mapping file paths to new content
        
    Returns:
        Status message about feature implementation
    """
    modified_files = []
    
    for file_path, content in file_changes.items():
        path = Path(file_path)
        
        # Create parent directories if needed
        path.parent.mkdir(parents=True, exist_ok=True)
        
        # Write file content
        path.write_text(content)
        modified_files.append(str(path))
    
    return f"""🔨 **Implementing**: {feature_name}

**Implementation Details**:
{implementation_details}

**Modified Files**: {len(modified_files)}
{chr(10).join(f"- {f}" for f in modified_files)}

✅ **Completed**: Feature implementation"""


def run_tests(
    test_command: str,
    test_path: str,
    tool_context: ToolContext
) -> str:
    """Run tests and analyze results.
    
    Args:
        test_command: Command to run tests
        test_path: Path to test files
        
    Returns:
        Test execution results
    """
    try:
        result = subprocess.run(
            test_command.split(),
            cwd=test_path,
            capture_output=True,
            text=True,
            timeout=60
        )
        
        return f"""🧪 **Testing**: Running test suite

**Command**: {test_command}
**Path**: {test_path}
**Exit Code**: {result.returncode}

**Output**:
{result.stdout}

**Errors**:
{result.stderr}

**Status**: {'✅ PASSED' if result.returncode == 0 else '❌ FAILED'}
"""
    
    except subprocess.TimeoutExpired:
        return "🧪 **Testing**: Test execution timed out after 60 seconds"
    except Exception as e:
        return f"🧪 **Testing**: Error running tests: {str(e)}"


def manage_git_workflow(
    action: str,
    branch_name: str,
    commit_message: str,
    tool_context: ToolContext
) -> str:
    """Manage git workflow operations.
    
    Args:
        action: Git action to perform (branch, commit, push, etc.)
        branch_name: Name of the branch for branch operations
        commit_message: Commit message for commit operations
        
    Returns:
        Status message about git operation
    """
    try:
        if action == "create_branch" and branch_name:
            result = subprocess.run(
                ["git", "checkout", "-b", branch_name],
                capture_output=True,
                text=True
            )
            return f"🌿 **Git**: Created and switched to branch '{branch_name}'"
            
        elif action == "commit" and commit_message:
            # Add all changes
            subprocess.run(["git", "add", "."], capture_output=True)
            
            # Commit changes
            result = subprocess.run(
                ["git", "commit", "-m", commit_message],
                capture_output=True,
                text=True
            )
            return f"🌿 **Git**: Committed changes with message: '{commit_message}'"
            
        elif action == "status":
            result = subprocess.run(
                ["git", "status", "--porcelain"],
                capture_output=True,
                text=True
            )
            return f"🌿 **Git**: Repository status:\n{result.stdout}"
            
        else:
            return f"🌿 **Git**: Unknown action '{action}'"
            
    except Exception as e:
        return f"🌿 **Git**: Error performing {action}: {str(e)}"


def update_task_status(
    spec_name: str,
    task_index: int,
    completed: bool,
    project_folder: Optional[str] = None,
    tool_context: ToolContext = None
) -> str:
    """Update the status of a specific task.
    
    Args:
        spec_name: Name of the specification
        task_index: Index of the task to update (0-based)
        completed: Whether the task is completed
        project_folder: Optional project folder path (if None, uses current directory)
        
    Returns:
        Status message about task update
    """
    # Determine the base directory
    if project_folder:
        base_dir = Path(project_folder)
    else:
        base_dir = Path(".")
    
    # Find the spec directory
    agent_os_dir = base_dir / ".agent-os"
    specs_dir = agent_os_dir / "specs"
    
    if not specs_dir.exists():
        return "❌ No specs directory found"
    
    # Find matching spec folder
    spec_folders = [d for d in specs_dir.iterdir() if spec_name.lower() in d.name.lower()]
    
    if not spec_folders:
        return f"❌ No specification found matching '{spec_name}'"
    
    spec_folder = spec_folders[0]
    tasks_file = spec_folder / "tasks.md"
    
    if not tasks_file.exists():
        return f"❌ No tasks.md file found in {spec_folder}"
    
    # Read and update tasks
    content = tasks_file.read_text()
    lines = content.split('\n')
    
    task_lines = [i for i, line in enumerate(lines) if line.strip().startswith('- [')]
    
    if task_index >= len(task_lines):
        return f"❌ Task index {task_index} out of range (0-{len(task_lines)-1})"
    
    line_index = task_lines[task_index]
    current_line = lines[line_index]
    
    if completed:
        lines[line_index] = current_line.replace('- [ ]', '- [x]')
        status = "completed"
    else:
        lines[line_index] = current_line.replace('- [x]', '- [ ]')
        status = "pending"
    
    # Write updated content
    tasks_file.write_text('\n'.join(lines))
    
    return f"✅ **Completed**: Updated task {task_index} to {status} in {spec_folder.name} (project: {base_dir.name})"


def create_documentation(
    doc_type: str,
    title: str,
    content: str,
    tool_context: ToolContext
) -> str:
    """Create documentation files.
    
    Args:
        doc_type: Type of documentation (README, API, etc.)
        title: Title of the documentation
        content: Content of the documentation
        
    Returns:
        Status message about documentation creation
    """
    if doc_type.lower() == "readme":
        file_path = Path("README.md")
    else:
        docs_dir = Path("docs")
        docs_dir.mkdir(exist_ok=True)
        file_path = docs_dir / f"{title.lower().replace(' ', '_')}.md"
    
    doc_content = f"""# {title}

{content}

---
*Generated by Agent OS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    file_path.write_text(doc_content)
    
    return f"📁 **Creating**: {doc_type} documentation at {file_path}"


# ---- Simics MCP tools (inlined from simics_mcp_tools.py) ----
# These functions provide Simics-specific helpers previously exposed via MCP.

from typing import Any, Dict
from dotenv import load_dotenv
import requests

FILE_BASE_DIR = Path(__file__).resolve().parent
load_dotenv()

SIMICS_KW_SEARCH_DOCS_PATH = FILE_BASE_DIR / "simics_doc_search_index.json"
DOCUMENT_DATA = None

DML_TPL_PATH = FILE_BASE_DIR / "simics-dml-tpl.dml"
DML_TEMPLATE = None

# Load optional data files if present
try:
    with open(SIMICS_KW_SEARCH_DOCS_PATH, 'r', encoding='utf-8') as file:
        DOCUMENT_DATA = json.load(file)
except FileNotFoundError:
    DOCUMENT_DATA = None

try:
    with open(DML_TPL_PATH, 'r', encoding='utf-8') as file:
        DML_TEMPLATE = file.read()
except Exception:
    DML_TEMPLATE = None


# Simics guide retrieval helpers
def __query_guide(query_list: list, wf: str = "guide") -> list:
    api_key_map = {
        "guide": os.getenv('API_KEY_GUIDE_WF'),
        "utility_doc": os.getenv('API_KEY_UTILITY_WF')
    }
    if wf not in api_key_map:
        raise ValueError(f"Workflow '{wf}' not supported")
    api_key = api_key_map[wf]
    if not api_key:
        raise ValueError(f"API key for workflow '{wf}' not found in environment (expected env var).")
    base_url = os.getenv('BASE_URL')
    if not base_url:
        raise ValueError("BASE_URL not found in environment variables")

    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }

    all_results = []
    seen_segment_ids = set()

    for query in query_list:
        try:
            payload = {
                "inputs": {"query": query},
                "response_mode": "blocking",
                "user": "simics-guide-agent"
            }

            response = requests.post(
                f"{base_url}/workflows/run",
                headers=headers,
                json=payload,
                timeout=60
            )

            response.raise_for_status()
            result_data = response.json()

            if 'data' in result_data and 'outputs' in result_data['data']:
                text_results = result_data['data']['outputs'].get('text', [])

                for item in text_results:
                    if isinstance(item, dict) and 'metadata' in item:
                        segment_id = item['metadata'].get('segment_id')
                        if segment_id and segment_id not in seen_segment_ids:
                            seen_segment_ids.add(segment_id)
                            item['source_query'] = query
                            all_results.append(item)

            # best-effort logging
        except requests.exceptions.RequestException:
            continue
        except Exception:
            continue

    all_results = [x.get("content") for x in all_results if isinstance(x, dict) and "content" in x]
    return all_results


def __format_guide_results(results: list, max_results: int = 10) -> str:
    if not results:
        return "No results found."
    formatted = f"Found {len(results)} unique results:\n\n"
    for i, result in enumerate(results[:max_results]):
        formatted += f"=== Result {i+1} ===\n"
        content_preview = result
        formatted += f"Content: {content_preview}\n\n"
    return formatted


def _q_guide(queries: str, max_results: int = 5, wf: str = "guide") -> str:
    try:
        if ',' in queries:
            query_list = [q.strip() for q in queries.split(',') if q.strip()]
        else:
            query_list = [queries.strip()]
        results = __query_guide(query_list, wf)
        return __format_guide_results(results, max_results)
    except Exception as e:
        return f"Error querying Simics guide: {str(e)}"


# Documentation search helpers
def __search_documents(documents_data: Dict[str, Any], keyword: str, case_sensitive: bool = False) -> List[Dict[str, str]]:
    results = []
    search_keyword = keyword if case_sensitive else keyword.lower()
    for document in documents_data.get('documents', []):
        document_title = document.get('title', '')
        for page in document.get('pages', []):
            page_title = page.get('title', '')
            for section in page.get('sections', []):
                section_title = section.get('title', '')
                section_url = section.get('url', '')
                section_text = section.get('text', '')
                search_text = section_text if case_sensitive else section_text.lower()
                if search_keyword in search_text:
                    results.append({
                        'document_title': document_title,
                        'page_title': page_title,
                        'section_title': section_title,
                        'section_url': section_url,
                        'text': section_text
                    })
    return results


def __search_multiple_keywords(documents_data: Dict[str, Any], keywords: List[str], case_sensitive: bool = False) -> List[Dict[str, str]]:
    all_results = []
    seen_urls = set()
    for keyword in keywords:
        results = __search_documents(documents_data, keyword, case_sensitive)
        for result in results:
            section_url = result.get('section_url', '')
            if section_url and section_url not in seen_urls:
                seen_urls.add(section_url)
                result['source_keyword'] = keyword
                all_results.append(result)
    return all_results


def __format_doc_search_results(results: List[Dict[str, str]], max_results: int = 10, offset: int = 0) -> str:
    if not results:
        return "No results found."
    if offset >= len(results):
        return "No more results! Your offset exceeds the length of all results."
    formatted = f"Showing Result {offset} to {offset + max_results - 1} ({len(results)} in total) unique document sections:\n\n"
    for i, result in enumerate(results[offset:offset + max_results]):
        formatted += f"=== Result {i+1} ===\n"
        formatted += f"Document: {result.get('document_title', 'N/A')}\n"
        formatted += f"Page: {result.get('page_title', 'N/A')}\n"
        formatted += f"Section: {result.get('section_title', 'N/A')}\n"
        if 'source_keyword' in result:
            formatted += f"Matched Keyword: {result['source_keyword']}\n"
        text = result.get('text', '')
        formatted += f"Text: {text}\n\n"
    return formatted


def query_simics_guide(queries: str, max_results: int = 5) -> str:
    """
    Semantically query the Simics documentation and concept guides. Use when you want to get know of a unfamiliar concept by ambiguous query or natural language. Can be used as a bootstrap.
    Documentation contained:
    - **Full DML 1.4 language specification**
    - **Model Builder User's Guide**, which focuses on modeling the behavior of a system. It contains:
        - *Introduction and Preparation*: Provides an overview of the way you model your hardware in Simics and how to map hardware concepts to Simics concepts.
        - *Basic Modeling Concepts*: The concepts of system modeling and how they map to modeling in Simics.
        - *Device Modeling*: Describes the device modeling concepts and introduces DML, the tool used for writing device models. Also includes chapters on writing new commands for the Simics CLI and how to define new interfaces between device models.
        - *Modeling Common Hardware Components*: Shows you how to model some common kinds of devices in Simics.
        - *Creating Virtual Systems*: Assembling the parts of a virtual system into a complete system. It also shows you how to deal with memory and address spaces in Simics. This is one of the most abstract parts of modeling a system in Simics and tries to map how software sees the hardware.
        - *Simics API*: Explain Simics API's major concepts, how it is structured, how it evolves, and some rules and conventions for how to use it. It also explains how the API interacts with Simics's multithreading support, and how to make your modules safe to use in multithreaded simulations.
    
    Args:
        queries: Comma-separated list of queries or single query
        max_results: Maximum number of results to return
        
    Returns:
        Formatted results from the Simics guide
    """
    try:
        res = _q_guide(queries, max_results)
        return res
    except Exception as e:
        return f"Error querying Simics guide: {str(e)}"


def get_dml_example() -> str:
    """
    Get the DML file example. This is the same as the DML template provided to you in the first message.
    Use this tool to recall the correct syntax of DML file.
        
    Returns:
        The content of the DML example.
    """
    return DML_TEMPLATE


def query_lib_doc(queries: str, max_results: int = 5) -> str:
    """
    Semantically query the Device Modeling Language documentation of the
    names, parameters and description of:
    - built-in templates, functions, methods, object attributes, object methods.
    - standard templates in `utility.dml`.
    - more about Simics library

    You can find usable templates, descriptions and methods of attributes, banks, connect,
    interface, port, subdevice, implement, registers, fields and events.

    Also suitable for keyword search as the doc contains many keywords.
    
    Args:
        queries: Comma-separated list of queries or single query
        max_results: Maximum number of results to return
        
    Returns:
        Formatted results from the Simics guide
    """
    try:
        res = _q_guide(queries, max_results, "utility_doc")
        return res
    except Exception as e:
        return f"Error querying Utility doc: {str(e)}"


def search_simics_docs(keywords: str, max_results: int = 10, offset: int = 0) -> str:
    """
    Search the full Simics documentation, API documentation, guides, code snippets and manuals by keyword match.
    You can search for a keyword here to get the descriptive content of it.
    
    Args:
        keywords: Comma-separated list of keywords or single keyword
        max_results: Maximum number of results to return
        offset: The offset of the results. Useful when you want to view more results of one set of keywords. This tool returns results[offset:offset + max_results]
        
    Returns:
        Formatted results from the Simics documentation search
    """
    try:
        # Parse keywords - support both single keyword and comma-separated list
        if DOCUMENT_DATA is None:
            return "Error: Documentation index not loaded."

        if ',' in keywords:
            keyword_list = [k.strip() for k in keywords.split(',') if k.strip()]
        else:
            keyword_list = [keywords.strip()]

        results = __search_multiple_keywords(DOCUMENT_DATA, keyword_list, False)
        return __format_doc_search_results(results, max_results, offset)
    except Exception as e:
        return f"Error reading documentation file: {str(e)}"


# Auto-build helpers
def __auto_build_srv_req(payload: dict, path: str = "/upload_code") -> dict:
    auto_build_srv = os.getenv("AUTO_BUILD_HOST_PORT")
    if not auto_build_srv or len(auto_build_srv) == 0:
        raise ConnectionError("Auto build server is not available now.")
    try:
        response = requests.post(
            f"{auto_build_srv}{path}",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=300
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.Timeout:
        raise TimeoutError("Build request timed out after 5 minutes.")
    except requests.exceptions.ConnectionError:
        raise ConnectionError(f"Could not connect to build server at {auto_build_srv}.")
    except requests.exceptions.RequestException as e:
        raise RuntimeError(f"Request failed - {str(e)}")
    except ValueError as e:
        raise ValueError(f"Invalid JSON response from server - {str(e)}")


def __auto_build(device_name: str, dml_content: str) -> str:
    try:
        job_id = str(int(datetime.now().timestamp() * 1000))
        payload = {
            "device_name": device_name,
            "upload_code": dml_content,
            "job_id": job_id
        }
        try:
            response_data = __auto_build_srv_req(payload, "/upload_code")
            compile_status = response_data.get("compile_status")
            if compile_status == 1:
                build_log = response_data.get("log", "No log available")
                return f"Build successful for device '{device_name}' (Job ID: {job_id})\n\nBuild Log:\n{build_log}"
            else:
                error_log = response_data.get("log", "No error log available")
                return f"Build failed for device '{device_name}' (Job ID: {job_id})\n\nError Log:\n{error_log}"
        except TimeoutError:
            return f"Error: Build request timed out after 5 minutes for device '{device_name}'"
        except ConnectionError as ce:
            return f"Error: {str(ce)}"
        except Exception as e:
            return f"Error: {str(e)}"
    except Exception as e:
        return f"Auto Build service is not available now. Error in auto_build function: {str(e)}"


def _auto_build(device_name: str, dml_path: str) -> str:
    try:
        with open(dml_path, 'r', encoding='utf-8') as file:
            dml_content = file.read()
        if len(dml_content) == 0:
            raise FileNotFoundError
    except FileNotFoundError:
        return f"Error: DML file not found or is empty at path: {dml_path}."
    except Exception as e:
        return f"Error reading DML file: {str(e)}"
    return __auto_build(device_name, dml_content)


def auto_build(device_name: str, dml_path: str, tool_context: ToolContext = None) -> str:
    # tool_context is accepted for API compatibility; mark used to avoid linter warnings
    _ = tool_context
    return _auto_build(device_name, dml_path)


def auto_build_by_content(device_name: str, dml_content: str, tool_context: ToolContext = None) -> str:
    # tool_context is accepted for API compatibility; mark used to avoid linter warnings
    _ = tool_context
    return __auto_build(device_name, dml_content)


# End of inlined simics tools
